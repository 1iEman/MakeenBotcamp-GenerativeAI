{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3KbeHseh4Xl"
   },
   "source": [
    "# üì¶ Day 3: Building a RAG System (Retrieval-Augmented Generation)\n",
    "\n",
    "Welcome to the third session of the Generative AI workshop!\n",
    "\n",
    "Today we'll learn how to **build a Retrieval-Augmented Generation (RAG) pipeline** using open-source tools. You'll see how to process documents, embed them into a vector store, and query them with a language model to generate intelligent responses grounded in real content.\n",
    "\n",
    "üéØ **Objectives**\n",
    "\n",
    "- Understand the concept and benefits of Retrieval-Augmented Generation (RAG)\n",
    "- Chunk and embed a document using `sentence-transformers`\n",
    "- Store and search document vectors using `ChromaDB`\n",
    "- Query a document using a local language model (`FLAN-T5`)\n",
    "- Build and test a simple QA system over a PDF ‚Äî no API keys required!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F48Ixn9qiuP0"
   },
   "source": [
    "## üîß Step 1: Install Required Packages\n",
    "\n",
    "We'll begin by installing all the necessary Python libraries for this RAG pipeline:\n",
    "\n",
    "- `chromadb` for vector storage and retrieval\n",
    "- `PyPDF2` for extracting text from PDF documents\n",
    "- `transformers` for loading our language model (FLAN-T5)\n",
    "- `sentence-transformers` for generating text embeddings\n",
    "\n",
    "This may take a minute the first time you run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdTUshycXdDe"
   },
   "outputs": [],
   "source": [
    "!pip install chromadb PyPDF2 transformers sentence-transformers --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLeupceli0fY"
   },
   "source": [
    "## üì¶ Step 2: Import Required Libraries\n",
    "\n",
    "Now that we've installed our dependencies, let's import the necessary libraries:\n",
    "\n",
    "- `PyPDF2` to read PDF files\n",
    "- `sentence-transformers` to embed text chunks\n",
    "- `transformers` to load and run our LLM (FLAN-T5)\n",
    "- `chromadb` to store and retrieve vectorized document chunks\n",
    "- `torch` as the backend for running the language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13-zYsnBXhAB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chihMEL8i9f8"
   },
   "source": [
    "## üìÑ Step 3: Upload and Extract Text from a PDF\n",
    "\n",
    "We'll now upload a PDF file using Colab's file uploader and extract its text content.\n",
    "\n",
    "- This step reads each page of the PDF using `PyPDF2`\n",
    "- It joins the extracted text into a single string\n",
    "- The resulting `full_text` variable will be used for chunking and embedding in the next steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aY5EaiMbOZIq",
    "outputId": "92b895e4-acef-46a8-b4b7-719e9b9e1556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.3\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "9XNRAfB_OO4y",
    "outputId": "51fd42a8-104a-43da-f9e3-5260a3ac370c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5bca13e4-6db8-47d0-9bdd-43a00a63a2a8\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-5bca13e4-6db8-47d0-9bdd-43a00a63a2a8\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Eman_CV.pdf to Eman_CV.pdf\n",
      "‚úÖ PDF uploaded and processed!\n",
      "üìÑ Filename: Eman_CV.pdf\n",
      "üìù Total text length: 5010 characters\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# TODO: Upload a PDF file from your computer\n",
    "uploaded = files.upload()  # Hint: What method allows users to upload files?\n",
    "\n",
    "# TODO: Get the filename of the uploaded file\n",
    "filename = next(iter(uploaded))  # Hint: What variable contains the uploaded files?\n",
    "\n",
    "# TODO: Create a PDF reader object\n",
    "reader = fitz.open(filename)  # Hint: What variable contains the filename?\n",
    "\n",
    "# Extract all text from the PDF\n",
    "# TODO: Extract text from each page and join into a single string\n",
    "cleaned_pages = []\n",
    "for page in reader:\n",
    "    words = page.get_text(\"words\")  # Extract individual words as (x0, y0, x1, y1, \"word\", block_no, line_no, word_no)\n",
    "    words.sort(key=lambda w: (w[1], w[0]))  # Sort by y0 (top-down), then x0 (left-right)\n",
    "    text = \" \".join(w[4] for w in words)  # Join just the word text with a single space\n",
    "    cleaned_pages.append(text.strip())\n",
    "\n",
    "full_text = \"\\n\".join(cleaned_pages)\n",
    "\n",
    "print(f\"‚úÖ PDF uploaded and processed!\")\n",
    "print(f\"üìÑ Filename: {filename}\")\n",
    "print(f\"üìù Total text length: {len(full_text)} characters\")\n",
    "\n",
    "# üí° LEARNING NOTES:\n",
    "# - This step reads each word on the page and ensures clean spacing\n",
    "# - It joins words in the correct visual order (left to right, top to bottom)\n",
    "# - We use 'words' mode in PyMuPDF to avoid messy newlines or irregular gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQ0yuCWNOtLG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "V6y0SONvOvPi",
    "outputId": "b982eada-075a-4ee1-c6ed-b9723789f88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAN ALHAJRI Artificial intelligence and Data Science Specialist Muscat, Al-Seeb| +968 94428223 | emaanhajri@gmail.com Github: https://github.com/1iEman | Linkedin: www.linkedin.com/in/eman-al-hajri EDUCATION‚Äã Sultan Qaboos University ALkhoud, Muscat Bachelor of Computer Science 2019-2025‚Äã Major in Artificial Intelligence and Data Science Cumulative GPA: 3.55/4.0, Dean‚Äôs List: 2021,2022,2023,2024 Relevant Coursework: Artificial Intelligence courses; Data Analysis and Visualization with Python, Machine learning, Deep Learning, Computer Vision, Pattern Recognition and analysis, Digital Image Processing, Mobile robotics, Natural Language Processing. Final Year Project in AI and Data Science. EXPERIENCE Makeen Bootcamp ‚Äì AI & Data Science Stream Apr 2025 ‚Äì Present Data Collection & Pipelines: Web scraping for data collection, building automated workflows using Apache Airflow.‚Äã management.‚Äã Infrastructure & Databases: Devops using Docker & MySQL for data storage and Visualization, Statistic\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display the first 1000 characters of the extracted text\n",
    "print(full_text[:1000])  # Hint: What variable contains our text and how many characters should we show?\n",
    "\n",
    "# üí° This is helpful for:\n",
    "# - Verifying that the PDF contains valid text (not just images)\n",
    "# - Understanding what content the model will later use for answering questions\n",
    "# - Checking if the text extraction worked properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv2_oa4JkIHb"
   },
   "source": [
    "## üëÄ Optional: View Extracted Text\n",
    "\n",
    "Let‚Äôs preview the extracted text from the PDF to ensure it was loaded correctly.\n",
    "\n",
    "This is helpful for:\n",
    "- Verifying that the PDF contains valid text (not just images)\n",
    "- Understanding what content the model will later use for answering questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkvzjDBtjGMa"
   },
   "source": [
    "## ‚úÇÔ∏è Step 4: Chunk the Text\n",
    "\n",
    "To make the text manageable for embedding and retrieval, we'll break the PDF content into smaller chunks.\n",
    "\n",
    "- This function splits the text into sentences using regular expressions\n",
    "- It groups sentences together until a character limit (e.g., 300) is reached\n",
    "- The result is a list of `chunks`, each suitable for embedding in the next step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKvHQLRBZCV9",
    "outputId": "410a167d-2935-4308-9baa-2504cb47530a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text chunked successfully!\n",
      "üìä Total chunks created: 21\n",
      "üìè Average chunk length: 238 characters\n",
      "üîç First chunk preview:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Clean the text first\n",
    "full_text1 = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "\n",
    "def chunk_text(text, max_length=300):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    chunks, chunk = [], \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(chunk) + len(sentence) <= max_length:\n",
    "            chunk += sentence + \" \"\n",
    "        else:\n",
    "            chunks.append(chunk.strip())\n",
    "            chunk = sentence + \" \"\n",
    "    if chunk:\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(full_text1)\n",
    "\n",
    "print(f\"‚úÖ Text chunked successfully!\")\n",
    "print(f\"üìä Total chunks created: {len(chunks)}\")\n",
    "print(f\"üìè Average chunk length: {sum(len(c) for c in chunks) / len(chunks):.0f} characters\")\n",
    "print(f\"üîç First chunk preview:\\n{chunks[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhBCo3Wokgee"
   },
   "source": [
    "## üìö Optional: Inspect the Chunks\n",
    "\n",
    "Let‚Äôs inspect a few individual chunks to understand how the original text was segmented.\n",
    "\n",
    "This helps you:\n",
    "- See how the chunking logic grouped sentences together\n",
    "- Verify whether the chunks are clean and meaningful for embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YHBPN2sjkhUF",
    "outputId": "5bca5002-3b42-492d-f95b-2aa2fad97514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "EMAN ALHAJRI Artificial intelligence and Data Science Specialist Muscat, Al-Seeb| +968 94428223 | emaanhajri@gmail.com Github: https://github.com/1iEman | Linkedin: www.linkedin.com/in/eman-al-hajri EDUCATION‚Äã Sultan Qaboos University ALkhoud, Muscat Bachelor of Computer Science 2019-2025‚Äã Major in Artificial Intelligence and Data Science Cumulative GPA: 3.55/4.0, Dean‚Äôs List: 2021,2022,2023,2024 Relevant Coursework: Artificial Intelligence courses; Data Analysis and Visualization with Python, Machine learning, Deep Learning, Computer Vision, Pattern Recognition and analysis, Digital Image Processing, Mobile robotics, Natural Language Processing.\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Final Year Project in AI and Data Science.\n",
      "\n",
      "--- Chunk 4 ---\n",
      "EXPERIENCE Makeen Bootcamp ‚Äì AI & Data Science Stream Apr 2025 ‚Äì Present Data Collection & Pipelines: Web scraping for data collection, building automated workflows using Apache Airflow.‚Äã management.‚Äã Infrastructure & Databases: Devops using Docker & MySQL for data storage and Visualization, Statistics & Collaboration: Apache Superset for dashboards, applied statistics for data interpretation, GitHub.\n",
      "\n",
      "--- Chunk 5 ---\n",
      "AI & Model Development: Machine Learning and Deep Learning applied in Computer Vision (CV) and Natural Language Processing (NLP), including Large Language Models (LLMs).\n",
      "\n",
      "--- Chunk 6 ---\n",
      "UNIVERSITY PROJECTS Developing the first Omani AI system for species detection and classification from wildlife images captured in Omani natural reserves 2024-2025 Utilizing Few-Shot learning techniques and Mega-detector tool built on YOLO architecture.\n",
      "\n",
      "--- Chunk 7 ---\n",
      "Named Entity Recognition (NER) for the De-identification of Protected Health Information (PHI) 2024-2025 Exploring Natural Language Processing(NLP) by using regular expression and Support Vector Machine model (SVM).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Loop through the first 3 chunks\n",
    "for i in range(7):  # Hint: How many chunks do we want to see?\n",
    "    print(f\"--- Chunk {i + 1} ---\")  # Hint: What variable represents the current chunk number? i + 1?\n",
    "    print(chunks[i])  # Hint: What list contains our chunks and what index are we at?\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUf6gKZ5jMZo"
   },
   "source": [
    "## üß¨ Step 5: Generate Embeddings\n",
    "\n",
    "We‚Äôll now convert each text chunk into a numerical vector using a pre-trained sentence embedding model.\n",
    "\n",
    "- We're using the `all-MiniLM-L6-v2` model from `sentence-transformers`\n",
    "- These embeddings will later be stored in a vector database for retrieval\n",
    "\n",
    "Each chunk is now represented in a way that a machine learning model can understand semantically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597,
     "referenced_widgets": [
      "f40c1110abe44ef68bc5b66ae1aaa12d",
      "93a9a271610a40bb946beced0688f2ff",
      "9ab6169895bb4f9cabf0210e1c1ef2da",
      "ee1b5bb861494657ae6702da7690e5a1",
      "c48057e8959d4656be1d1e3170c94a77",
      "f12c380f0fa74486b6ceec3f55d3fe53",
      "809840244b994251835a15d86ae6dcdf",
      "61946c4e67414c9fa390958544330377",
      "71ce047faa8647bea3d8a76cdc1a945c",
      "9b5458e7e98c4597beb936fa506bd969",
      "6b40d5095fbc4e468deba6f9b9e0140f",
      "eeb2fd9cbcfb4dc982db2b72dd20f556",
      "3e2d56116bb643e4890d4faba979ee17",
      "466d48ae141e4cf1b656a0030e59f126",
      "cd5a358b6fb8486795c65a0d180d5c6d",
      "fb83490d607743ddb946141839964fa2",
      "0739639deb51416b95fc3d195f046378",
      "11cf7dae70c5407aae906e8340803d78",
      "0b521286344f457cbd64e8fa360fd3b6",
      "2264000e20764f4f93c21244a19856f2",
      "1b87c724d2b94a598fb116c4572a478b",
      "a9c8bd46dd004430a56c62dbed4ad47b",
      "d249e51135194be98368e49b6938bc08",
      "8772df3478164eb1bfbd1736cc4a4cfc",
      "74300c0da344400ca8f5c75f84cd4d4d",
      "d6f71db1c04d4ff7be7fd1c0e1503cfe",
      "f6d8191214b9489e8243604dd9405821",
      "76af409d158d475ea3469e2e7903ba0c",
      "903e6b1fa0bb4d25876cfbf34524528d",
      "0c5f9064ae144e919dc6420a05e2649e",
      "be43e4c5d9b248b4b6a96f899e25fd69",
      "20e46ea6caac4f6588776d4f750a55b2",
      "a8a63999bcfe43fab4f7f4c23f1f7854",
      "e599fb2b469a4f6ba2b7d19978368334",
      "366f943c36bb46ffad22e6b39620984c",
      "a39b39e65df94346a4c85943729bf9a2",
      "fd01e95addca4e5bafc0ecac038afa83",
      "406484a212fe42a1ab487d0529e1984b",
      "0e6abf613c0e491fb30f604b36309230",
      "f0b583afb6bc4854b37282cb939c058e",
      "fe74887089ec4e0fa658bc05c9b49521",
      "5e2a48ce7c274fab981d3a610e6ab68f",
      "00a2814609b14e4eaf21cfd3155c1e44",
      "e59629cd5dbf4b218cfde2a92e988374",
      "86e6c4a9b2464b72ae3ad33d61244af8",
      "8f10852eb50c4e59ad2ee0ef7bc0ec51",
      "28f9bdc6cc1541e2ab50cf8c99d8a99e",
      "04734e87816a4f159f1f0288087b9d2c",
      "258d432aa4a34a0f9cc15ff12cdedde4",
      "42ae72ffd9c84c0abcb4fed0f0b749c5",
      "bc176b6e7d384dca8afaada3e908d31e",
      "8bc4e4ba18eb46ce9be6303ba853445a",
      "9ec9892d78c440989ea4624fbcbe5bd7",
      "7d923e3beb284b2fbada083d7b89a6fd",
      "4254e56dfbd44d038e7b4742b8df5c30",
      "57ca28dbe3e84708bc615132a0c21bec",
      "96350be4b40d4f839dd5ccaa6633c447",
      "9dd2a31e448d4a31984f112d93e1d970",
      "1cc9dd0c1537463ba32066f6334c08cf",
      "088eb02f9dd1457fb0347ea2bd62c39a",
      "c434487ccdb443e08ed5c601f9c7161d",
      "5f6353108aa94049be588448b16eac3f",
      "92326a3b648046c88918b836aef5c27f",
      "978d843db59543cf9599086847a438af",
      "a56e9155f100475992a6c67851672d40",
      "d570e81ffe134d0cbaedbb51e14c94c8",
      "f0a66c14da9943f0bd9a839f34ed6e07",
      "9574b52e54434456900a974dd9b40924",
      "e4972c8863944b8898aff5749b660e70",
      "d95e403e5a2c45bdb5ede4f85b15f6bc",
      "b843969b93754661b9b80bcf2db6c010",
      "c9be081dc8d549ce83e2df75fea7c466",
      "052964c8b3ac441ea71ba9bf90b0f4d0",
      "bdef632e290b40aeaaaa72c651e2c91d",
      "5e195f3bdfbd4fbcbb8d008c06e7a76c",
      "a91d6775ebdf44e786023a76d14bb56c",
      "11c0bc81b1d64ec580021abce994b7e3",
      "446e7e57791a43ec936a5205947ecf75",
      "dea7846cdf90486fb97933f9da5e389f",
      "7d8a6413717b4137a30625e71f855886",
      "bbda32e554ff41098f2b7b1ff0862b29",
      "df7babf8b37b4965b3f0ce5398983058",
      "e1c9b9bb1fad46d7b35c23880da9e48f",
      "0c25123a22624192916419f77f794d2d",
      "2e30351e47e64285898353fd5f94d032",
      "f6e05e9c8a284a3794b81f3ede0eebbe",
      "1750425ff3a747c183b8b19a9066d0db",
      "cd4028ee1800470fb7a8679316429bad",
      "a7741ec7fb5544979370e0e22823962b",
      "1c92608f6be14ffdbb416bfe7eedacfa",
      "70070f80bc2a499fac799928807d5c17",
      "2d57e93faa0b49708c856a38bf389b5b",
      "d4f408cb7e4143979e22a391c970cc16",
      "b4651e24826d417aa09c8c278cbded21",
      "106dc8d878774e0792828d94142f7641",
      "fb0b0cb74d4c4b85ac037505006911e8",
      "f3c0900b2bc44bc691010c8acfdf85ec",
      "99bc893017f948a1addc28bcc9e2fdfa",
      "184b6778a9b74acb80ce2312751cb533",
      "0f4aaa3beda1429bb277d77f2a3d6528",
      "4b1171da0e92466690e1b7c30c8d0618",
      "c10c6a09a4d742d19bf26a04da7b5553",
      "a76399e1b7c242a28581a5024bc8d484",
      "732c17b9032a4dd08445c5131afbd2d9",
      "a248d09d0346447f885b39a08af20504",
      "8aa946b3dd3844d095f512acad0e18d7",
      "bb09a89231184987b518d245ae7f9fa5",
      "d3cbbcca3d034d559509f470bec9b462",
      "498bb15e17fa44d590c2af96a10db741",
      "685b1105b0064654bdc5f7e81aa870a8",
      "e0594c95f738476b824a8aba496139e4",
      "2e0c68600ed84d58a7709a84365b4ebb",
      "099b362f5a174bce9619fd855e4202cf",
      "048543ad8e4e40d1a42d34cf4b68f072",
      "a53a6e48bb204ef5aee8dc1a44c5f03e",
      "94fbab8ca35e4304939982ac4ade1c32",
      "ba3a4ac2dab84a6a9753faafc3110865",
      "a0d5c2ce0880481db87d1ef718ec0e5e",
      "234fc3d1bbb64f29be217881b872e992",
      "a5d608f8cc1f441f9401f0c8985fbfbb",
      "cfc424ad006f406fb0fd3b5a0d84e601"
     ]
    },
    "id": "4NjToc0uZlUh",
    "outputId": "3100c303-f35a-4f24-ef51-af82d0688bf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c1110abe44ef68bc5b66ae1aaa12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb2fd9cbcfb4dc982db2b72dd20f556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d249e51135194be98368e49b6938bc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e599fb2b469a4f6ba2b7d19978368334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e6c4a9b2464b72ae3ad33d61244af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ca28dbe3e84708bc615132a0c21bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a66c14da9943f0bd9a839f34ed6e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446e7e57791a43ec936a5205947ecf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7741ec7fb5544979370e0e22823962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4aaa3beda1429bb277d77f2a3d6528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0594c95f738476b824a8aba496139e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings created successfully!\n",
      "üìä Number of embeddings: 21\n",
      "üìè Embedding dimension: 384\n",
      "üîç First embedding preview (first 10 values):\n",
      "[-0.11883842  0.04829862 -0.00254814 -0.01101124  0.05195079  0.0102918\n",
      "  0.11543332  0.0007007  -0.08592541 -0.070654  ]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Initialize a sentence transformer model for creating embeddings\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Hint: What's the model name for all-MiniLM-L6-v2?\n",
    "\n",
    "# TODO: Convert all chunks into embedding vectors\n",
    "embeddings = embedder.encode(chunks)  # Hint: What method creates embeddings and what variable contains our chunks?\n",
    "\n",
    "print(f\"‚úÖ Embeddings created successfully!\")\n",
    "print(f\"üìä Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"üìè Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"üîç First embedding preview (first 10 values):\")\n",
    "print(embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4Wuid6ClhqF"
   },
   "source": [
    "## üîé Optional: Inspect Embeddings\n",
    "\n",
    "Let‚Äôs take a quick look at the generated embeddings.\n",
    "\n",
    "- Each embedding is a high-dimensional vector representing the meaning of a chunk\n",
    "- These vectors are what the model uses to retrieve relevant information later\n",
    "\n",
    "Note: Embeddings are large arrays of numbers, so we‚Äôll only display the first one for illustration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rix46NfElilx",
    "outputId": "4d5e122e-3942-4688-c9b8-52f8adb953d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for Chunk 1 (dimension: 384):\n",
      "[-1.18838422e-01  4.82986234e-02 -2.54813721e-03 -1.10112354e-02\n",
      "  5.19507863e-02  1.02917971e-02  1.15433320e-01  7.00698933e-04\n",
      " -8.59254077e-02 -7.06540048e-02  1.33175042e-03 -3.54724042e-02\n",
      "  1.84340514e-02 -6.73720986e-03  2.44030710e-02 -2.95030996e-02\n",
      " -5.81384338e-02 -5.04396111e-02 -2.07655355e-02  2.90359166e-02\n",
      " -6.36760369e-02  2.40299329e-02  2.62433402e-02 -6.03735121e-03\n",
      " -1.10766171e-02 -1.40066631e-03 -1.86198559e-02  3.27700749e-02\n",
      "  2.88602617e-03 -5.69439270e-02 -4.39416729e-02  2.54140683e-02\n",
      "  8.79094303e-02 -2.49911081e-02 -3.66832465e-02  6.24138303e-03\n",
      " -6.64680302e-02 -6.71444014e-02  2.05642469e-02  4.23887521e-02\n",
      "  2.18802430e-02 -4.28824984e-02 -3.43770310e-02  6.14668801e-02\n",
      "  6.56373054e-02 -7.85202682e-02  2.94870026e-02  1.07982671e-02\n",
      "  6.33241981e-02 -4.50847223e-02 -1.82340480e-02 -2.77211033e-02\n",
      " -3.67373996e-03 -3.65946442e-02  5.42501844e-02 -2.08566878e-02\n",
      "  1.50349056e-02 -6.00950569e-02  1.63938235e-02 -3.32385935e-02\n",
      "  1.75034441e-02 -5.95252262e-04 -1.63483724e-01  8.49208236e-02\n",
      " -7.58383125e-02  1.61098354e-02  4.83830236e-02 -7.59816635e-03\n",
      " -2.49854662e-02  5.94974011e-02  6.58898875e-02 -3.51373367e-02\n",
      "  8.84333916e-04 -1.15679748e-01  4.93902452e-02  3.36046852e-02\n",
      "  5.51542155e-02  2.63837632e-02  5.36946431e-02  3.89323011e-02\n",
      "  4.39265714e-04  1.80604812e-02 -9.28824693e-02 -4.07394301e-03\n",
      " -8.23453476e-04 -4.88312170e-02 -6.67750509e-03 -2.35417765e-02\n",
      " -3.81330922e-02  5.24515510e-02 -4.24937494e-02 -5.58997616e-02\n",
      "  8.68158191e-02 -4.89617065e-02 -8.33967254e-02 -4.57634851e-02\n",
      "  2.90422533e-02  3.46577317e-02 -8.64918306e-02  4.06218529e-01\n",
      "  3.59495506e-02  1.86971370e-02  9.79783311e-02 -7.86515325e-03\n",
      "  2.37141307e-02 -5.75650968e-02 -6.10997640e-02 -6.62039267e-03\n",
      "  7.05990987e-03  2.16697901e-02 -2.44050901e-02 -3.35146897e-02\n",
      "  2.50123470e-04  3.17077525e-02  4.40715365e-02  9.46326479e-02\n",
      " -3.55799496e-02 -4.53424687e-03  4.37148847e-02  2.05020158e-04\n",
      " -2.85862410e-03 -2.48840358e-02  3.76082095e-03  1.40412971e-02\n",
      "  7.78158009e-02 -1.32314444e-01  6.87638344e-03 -7.22012508e-33\n",
      "  7.33462675e-03  2.72612507e-03  1.21475346e-02 -2.44027795e-03\n",
      "  2.79325377e-02  3.92706506e-02  3.74389114e-03 -4.64352481e-02\n",
      " -1.44924922e-02  5.36019355e-02  6.59066811e-03  3.66479419e-02\n",
      " -2.31356248e-02  3.27537619e-02  7.81109557e-02  9.62741766e-03\n",
      "  7.96406996e-03  2.87430920e-03 -1.88063341e-03  4.69162548e-03\n",
      " -1.24022122e-02 -8.04186100e-04 -2.30386723e-02  4.29727994e-02\n",
      " -2.82600746e-02 -6.69464841e-02  3.85390036e-02 -7.08571076e-02\n",
      "  2.01093052e-02  1.46027934e-03  1.46402058e-03  4.99123558e-02\n",
      " -2.59455219e-02  8.22367612e-04 -3.75727154e-02 -2.87406947e-02\n",
      "  3.33750062e-02 -7.46282786e-02 -3.59838903e-02  2.56807897e-02\n",
      " -5.01390249e-02  1.08372569e-02 -4.24378887e-02 -2.66858214e-03\n",
      " -4.91628703e-03  1.66479215e-01 -1.15401496e-03 -4.96057747e-03\n",
      " -6.48220703e-02  6.97621927e-02 -2.81817210e-03 -2.13251524e-02\n",
      " -1.16136923e-01  4.33386639e-02 -3.35092749e-03 -2.01066211e-02\n",
      "  1.65538844e-02 -4.39711288e-02  2.06195172e-02 -9.08994116e-03\n",
      "  9.71363485e-03  3.93914506e-02 -1.24877226e-02  9.35017318e-03\n",
      " -8.64778459e-02 -4.85176742e-02  2.44777519e-02 -8.49496014e-03\n",
      "  2.30635684e-02 -1.26382308e-02 -5.10100387e-02  3.67599390e-02\n",
      "  3.77174988e-02  3.09160817e-02 -2.87984330e-02 -1.92688070e-02\n",
      " -1.98316723e-02  3.58351693e-02  8.06306526e-02  6.49723504e-03\n",
      "  3.54553089e-02 -4.19588350e-02  6.69399276e-03 -2.40788702e-02\n",
      "  9.50236842e-02  5.46349064e-02  4.22102259e-03 -5.18073775e-02\n",
      "  1.02152089e-02 -4.10985127e-02 -3.57456692e-02  6.13181256e-02\n",
      " -3.09439888e-03  8.79616886e-02  6.00080239e-03  4.49256602e-33\n",
      " -7.71675706e-02  1.89930517e-02 -3.57382372e-02  8.87979195e-02\n",
      " -1.75550785e-02 -2.76266551e-03  3.72739658e-02  9.01367888e-02\n",
      " -9.25044864e-02  6.80300072e-02  2.23901775e-02 -4.50896323e-02\n",
      "  3.08789387e-02  4.44951728e-02 -5.79953939e-03  3.52336057e-02\n",
      "  6.96883202e-02 -4.06341534e-03 -2.81551033e-02 -3.57294567e-02\n",
      " -3.05071697e-02 -3.23784910e-02 -2.49982206e-03  3.49294581e-02\n",
      " -4.14807610e-02  3.02052423e-02  4.85891812e-02  6.32987991e-02\n",
      " -2.16931701e-02  3.68004516e-02  3.89656611e-02 -2.35814471e-02\n",
      " -5.06326146e-02 -5.82029372e-02  4.82625179e-02  8.40441212e-02\n",
      "  3.67810428e-02 -7.77033973e-04  2.48482488e-02 -5.05173057e-02\n",
      "  3.96690741e-02 -1.00827664e-02  2.24444293e-03  1.16977185e-01\n",
      " -2.19612811e-02 -5.80601301e-03 -4.80929390e-02  3.78877763e-03\n",
      "  3.51726599e-02  7.72972181e-02 -9.31972042e-02 -1.19928848e-02\n",
      " -2.19681393e-02  4.12943177e-02 -2.29582246e-02  4.16049361e-03\n",
      " -4.32186872e-02  7.02131763e-02 -1.90595072e-02  4.75389534e-04\n",
      "  5.48075698e-03  2.67613959e-02 -3.36127840e-02  1.34685980e-02\n",
      " -2.27466468e-02  3.87389809e-02 -2.45232563e-02 -3.63281891e-02\n",
      " -1.79248909e-03 -5.25698327e-02  6.68947306e-03 -2.58465428e-02\n",
      " -1.34835348e-01  1.13943208e-03 -4.71694097e-02 -5.34748547e-02\n",
      " -1.84271559e-02 -7.30421348e-03 -9.65704583e-03 -3.77262570e-02\n",
      " -3.39999758e-02  1.84173640e-02 -8.00309423e-03 -5.51225850e-03\n",
      " -3.35320048e-02 -2.01806203e-02  2.16658320e-02  1.07582584e-02\n",
      " -5.74746542e-02  1.96967274e-02 -7.24099902e-03  2.30371151e-02\n",
      "  1.20233946e-01  3.24196904e-03  1.01499865e-02 -1.34036666e-08\n",
      " -4.67245430e-02  4.06205915e-02 -5.56163751e-02 -1.88537594e-03\n",
      "  5.63239790e-02  4.96388339e-02 -4.15416881e-02  3.25038880e-02\n",
      "  2.57491916e-02 -1.87810455e-02  6.92081302e-02  2.59879008e-02\n",
      " -2.78233401e-02  5.75752296e-02  9.12807882e-02 -1.53256776e-02\n",
      " -1.04720972e-01 -2.75859460e-02 -1.62227526e-02 -3.53991762e-02\n",
      " -1.04613248e-02 -1.39993485e-02 -2.94143101e-04 -8.36296678e-02\n",
      "  7.93231372e-03  6.96000271e-03 -4.42296229e-02  7.47582912e-02\n",
      "  7.44096041e-02 -4.05807570e-02 -1.82668527e-03  1.98500827e-02\n",
      "  1.43821528e-02  2.05854382e-02  2.21336894e-02 -6.43703863e-02\n",
      " -6.36985600e-02  1.61391385e-02  9.90726799e-03 -5.55964978e-03\n",
      " -5.46731390e-02 -2.33115312e-02  7.04692528e-02  6.46806601e-03\n",
      " -4.77000326e-02 -3.64718726e-03  7.83751719e-03 -4.97465255e-03\n",
      " -1.24185262e-02 -7.78120980e-02 -9.40937607e-04 -8.00256431e-03\n",
      "  6.03420986e-03  8.43493044e-02  1.07303761e-01  1.14277191e-02\n",
      "  1.33666676e-02 -1.27473138e-02  6.14544153e-02  3.56412940e-02\n",
      "  1.58745915e-01  1.26409411e-01  4.65490967e-02 -1.57173313e-02]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print information about the first embedding\n",
    "print(f\"Embedding for Chunk 1 (dimension: {len(embeddings[0])}):\")\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKxyfgmtjUry"
   },
   "source": [
    "## üóÇÔ∏è Step 6: Store Chunks in ChromaDB\n",
    "\n",
    "Now we‚Äôll store the chunks and their corresponding embeddings in a ChromaDB collection.\n",
    "\n",
    "- ChromaDB is an efficient local vector database\n",
    "- We create a collection named `\"test\"` (or reuse it if it already exists)\n",
    "- Each chunk is added along with its embedding and a unique ID\n",
    "\n",
    "This setup allows us to later search for relevant chunks based on user questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHb88axoZngR",
    "outputId": "5ae8bcff-8134-46ea-d103-76e9a83e50de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector database created successfully!\n",
      "üìä Total documents stored: 21\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a ChromaDB client with anonymized telemetry disabled\n",
    "chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))  # Hint: Should telemetry be enabled? True or False?\n",
    "\n",
    "# TODO: Create a collection to store our documents and embeddings\n",
    "collection = chroma_client.create_collection(name=\"pdf_chunks\", get_or_create=True)  # Hint: What should we name our collection and should we create if it exists?\n",
    "\n",
    "# TODO: Add documents and embeddings to the collection\n",
    "for i, (chunk, emb) in enumerate(zip(chunks, embeddings)):  # Hint: What two lists should we iterate through together?\n",
    "    collection.add(\n",
    "        documents=[chunk],  # Hint: What text chunk are we adding?\n",
    "        embeddings=[emb.tolist()],  # Hint: What embedding (converted to list) are we adding?\n",
    "        ids=[str(i)]  # Hint: What should be the unique ID for this document?\n",
    "    )\n",
    "\n",
    "print(f\"‚úÖ Vector database created successfully!\")\n",
    "print(f\"üìä Total documents stored: {collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-bYPRd_lxrj"
   },
   "source": [
    "## üìã Optional: Preview Stored Chunks in ChromaDB\n",
    "\n",
    "Let‚Äôs confirm that the chunks and embeddings were properly added to the ChromaDB collection.\n",
    "\n",
    "This quick check allows us to:\n",
    "- View some of the stored chunk texts\n",
    "- Ensure each one has a unique ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qw7bKLV1lzLY",
    "outputId": "225fa290-27cf-4ae4-ad1f-65cbabc0bfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Chunk ID: 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìÑ Chunk ID: 1\n",
      "EMAN ALHAJRI Artificial intelligence and Data Science Specialist Muscat, Al-Seeb| +968 94428223 | emaanhajri@gmail.com Github: https://github.com/1iEman | Linkedin: www.linkedin.com/in/eman-al-hajri EDUCATION‚Äã Sultan Qaboos University ALkhoud, Muscat Bachelor of Computer Science 2019-2025‚Äã Major in Artificial Intelligence and Data Science Cumulative GPA: 3.55/4.0, Dean‚Äôs List: 2021,2022,2023,2024 Relevant Coursework: Artificial Intelligence courses; Data Analysis and Visualization with Python, Machine learning, Deep Learning, Computer Vision, Pattern Recognition and analysis, Digital Image Processing, Mobile robotics, Natural Language Processing.\n",
      "--------------------------------------------------------------------------------\n",
      "üìÑ Chunk ID: 2\n",
      "Final Year Project in AI and Data Science.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: Retrieve documents from the collection\n",
    "results = collection.get(include=[\"documents\"])  # Hint: What type of data do we want to retrieve from the collection?\n",
    "\n",
    "# TODO: Display the first 3 documents\n",
    "for i in range(min(3, len(results[\"documents\"]))):  # Hint: How many documents to show and what key contains the documents?\n",
    "    print(f\"üìÑ Chunk ID: {results['ids'][i]}\")  # Hint: What key contains IDs and what index are we at?\n",
    "    print(results[\"documents\"][i])  # Hint: What key contains documents and what index are we at?\n",
    "    print(\"-\" * 80)  # Hint: What character should create a separator line?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "wpbEG-hf0jqZ",
    "outputId": "a358cfd0-fdbd-4fe9-aaa1-eaf9c108df8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2d5b926d-f4e6-47b6-b786-d9a399e66291\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-2d5b926d-f4e6-47b6-b786-d9a399e66291\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Aya Al Hasani.pdf to Aya Al Hasani (2).pdf\n",
      "‚úÖ Text chunked successfully!\n",
      "üìä Total chunks created: 9\n",
      "üìè Average chunk length: 363 characters\n",
      "üîç First chunk preview:\n",
      "Aya Khamis AL-Hasani Data Scientist & Data Engineer ABOUT ME EDUCATION I am passionate about AI and machine ‚Ä¢ University of Technology and Applied Sciences, learning, driven to apply these Muscat, Oman - 2024 technologies to solve real-world Bachelor‚Äôs Degree challenges.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings created successfully!\n",
      "üìä Number of embeddings: 9\n",
      "üìè Embedding dimension: 384\n",
      "üîç First embedding preview (first 10 values):\n",
      "[-0.055553    0.03918847  0.05182587  0.01580185 -0.0172099  -0.13430738\n",
      "  0.03710235 -0.02356444 -0.04780589  0.02980794]\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# TODO: Upload multiple PDF files from your computer\n",
    "uploaded = files.upload()  # This allows you to upload more than one PDF\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "# TODO: Loop through each uploaded file\n",
    "for filename in uploaded:\n",
    "    reader = fitz.open(filename)\n",
    "    cleaned_pages = []\n",
    "    for page in reader:\n",
    "        words = page.get_text(\"words\")\n",
    "        words.sort(key=lambda w: (w[1], w[0]))  # Sort top-down, then left-right\n",
    "        text = \" \".join(w[4] for w in words)\n",
    "        cleaned_pages.append(text.strip())\n",
    "    full_text = \"\\n\".join(cleaned_pages)\n",
    "\n",
    "    # Clean whitespace\n",
    "    full_text_clean = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "    all_texts.append(full_text_clean)\n",
    "\n",
    "# Combine all cleaned PDF texts into one\n",
    "combined_text = \" \".join(all_texts)\n",
    "\n",
    "# ‚úÖ Sentence-based chunking\n",
    "def chunk_text(text, max_length=300):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    chunks, chunk = [], \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(chunk) + len(sentence) <= max_length:\n",
    "            chunk += sentence + \" \"\n",
    "        else:\n",
    "            chunks.append(chunk.strip())\n",
    "            chunk = sentence + \" \"\n",
    "    if chunk:\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(combined_text)\n",
    "\n",
    "print(f\"‚úÖ Text chunked successfully!\")\n",
    "print(f\"üìä Total chunks created: {len(chunks)}\")\n",
    "print(f\"üìè Average chunk length: {sum(len(c) for c in chunks) / len(chunks):.0f} characters\")\n",
    "print(f\"üîç First chunk preview:\\n{chunks[0]}\")\n",
    "\n",
    "# ‚úÖ Create embeddings\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedder.encode(chunks)\n",
    "\n",
    "print(f\"‚úÖ Embeddings created successfully!\")\n",
    "print(f\"üìä Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"üìè Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"üîç First embedding preview (first 10 values):\")\n",
    "print(embeddings[0][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYhRcE0AjZsL"
   },
   "source": [
    "## ü§ñ Step 7: Load the Language Model (FLAN-T5)\n",
    "\n",
    "We‚Äôll now load a lightweight instruction-tuned language model to generate answers based on retrieved context.\n",
    "\n",
    "- `google/flan-t5-base` is a small and efficient model suitable for Q&A tasks\n",
    "- We load both the tokenizer and the model using Hugging Face Transformers\n",
    "\n",
    "This model will take the retrieved document chunks and generate context-aware answers to user questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqC0i6MSZtQg"
   },
   "outputs": [],
   "source": [
    "# TODO: Load the tokenizer for the T5 model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")  # Hint: What's the model name for google/flan-t5-base?\n",
    "\n",
    "# TODO: Load the T5 model for sequence-to-sequence generation\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")  # Hint: Should we use the same name?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB9iTnC2jhM4"
   },
   "source": [
    "## ‚ùì Step 8: Define a Question-Answering Function\n",
    "\n",
    "This function allows us to query the document using natural language and receive an answer generated by the language model.\n",
    "\n",
    "Here‚Äôs how it works:\n",
    "\n",
    "- It first embeds the user's question using the same embedding model as before\n",
    "- It then queries the ChromaDB collection to retrieve the most relevant text chunks\n",
    "- These chunks are used as context in a prompt passed to the `flan-t5-base` model\n",
    "- The model generates an answer based on the context and the question\n",
    "\n",
    "You can now ask the model questions about the uploaded PDF!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFYzu8AiZupm"
   },
   "outputs": [],
   "source": [
    "def ask_question(query):\n",
    "    # TODO: Convert the query into an embedding vector\n",
    "    query_vec = embedder.encode([query])[0]  # Hint: What method creates embeddings? What should we encode? What index for first result?\n",
    "\n",
    "    # TODO: Search for similar documents in the vector database\n",
    "    results = collection.query(query_embeddings=[query_vec.tolist()], n_results=3)  # Hint: What vector to search with? How many similar chunks to retrieve? Bonus: What if we are able to add a threshold?\n",
    "\n",
    "    # TODO: Combine retrieved documents into context\n",
    "    context = \" \".join(results[\"documents\"][0])  # Hint: What key contains the retrieved documents? What index for our query results?\n",
    "\n",
    "    # TODO: Create a prompt that includes context and question\n",
    "    instruction = \"You are a helpful assistant. Use the context to answer the question.\"\n",
    "    prompt = (\n",
    "        f\"{instruction}\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"  # Hint: What variable contains our retrieved context?\n",
    "        f\"Question: {query}\\n\\n\"  # Hint: What variable contains the user's question?\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    # Display the components before generating answer\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üîç QUERY:\")\n",
    "    print(f\"'{query}'\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìã INSTRUCTION:\")\n",
    "    print(instruction)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìÑ RETRIEVED CONTEXT:\")\n",
    "    print(context)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ü§ñ GENERATED ANSWER:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # TODO: Tokenize the prompt for the model\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")  # Hint: What should we tokenize? What tensor format does PyTorch use? (\"pt\")\n",
    "\n",
    "    # TODO: Generate an answer using the model\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200)  # Hint: What inputs should we pass? What's a reasonable token limit for answers?\n",
    "\n",
    "    # TODO: Decode and return the generated answer\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Hint: What outputs to decode? What index for first result? Should we skip special tokens?\n",
    "\n",
    "    # Extract only the answer part (after \"Answer:\")\n",
    "    if \"Answer:\" in full_response:\n",
    "        answer_start = full_response.find(\"Answer:\") + len(\"Answer:\")\n",
    "        answer = full_response[answer_start:].lstrip()  # Use lstrip() instead of strip() to preserve trailing whitespace\n",
    "    else:\n",
    "        answer = full_response.strip()  # Fallback if \"Answer:\" not found\n",
    "\n",
    "    print(answer)\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjlg0nfbjmls"
   },
   "source": [
    "## ‚ñ∂Ô∏è Step 9: Ask a Question!\n",
    "\n",
    "Let‚Äôs test the full pipeline by asking a question about the uploaded PDF.\n",
    "\n",
    "- This example asks the model to generate a bullet-point summary\n",
    "- You can replace the prompt with any question relevant to the document\n",
    "\n",
    "Try experimenting with different question styles to explore the model's capabilities!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "a0Tc5lxAZy_e",
    "outputId": "3a92e84f-5fd4-455f-d5f2-180ba31950bc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-7-3262428052.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Ask a question about the document content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mask_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What Aya specialist in ? \"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Hint: Write a question that would require information from your uploaded PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# üí° Try different types of questions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# - Factual questions about specific content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-6-1789700417.py\u001b[0m in \u001b[0;36mask_question\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# TODO: Search for similar documents in the vector database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Hint: What vector to search with? How many similar chunks to retrieve? Bonus: What if we are able to add a threshold?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# TODO: Combine retrieved documents into context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Ask a question about the document content\n",
    "ask_question(\"What Aya specialist in ? \")  # Hint: Write a question that would require information from your uploaded PDF\n",
    "\n",
    "# üí° Try different types of questions:\n",
    "# - Factual questions about specific content\n",
    "# - Summary requests\n",
    "# - Questions that require combining information from multiple chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcfiAFsnqk50"
   },
   "source": [
    "# üöÄ Advanced RAG Experiments\n",
    "## For Students Who Want to Go Further!\n",
    "\n",
    "Congratulations! You've built a complete RAG system. Now it's time to become a **real RAG researcher** and explore what makes these systems work better.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ **Choose Your Experiment Track**\n",
    "\n",
    "### üß© **Track 1: Chunking Strategy Optimization**\n",
    "**The Question**: How does text splitting affect answer quality?\n",
    "\n",
    "**Experiments to Try:**\n",
    "- **Chunk size comparison**: Test 100, 300, 500, 1000 character chunks\n",
    "- **Overlap experiments**: Add 50-100 character overlap between chunks\n",
    "- **Smart boundaries**: Split by paragraphs vs. sentences vs. fixed length\n",
    "- **Hybrid approaches**: Combine multiple splitting strategies\n",
    "\n",
    "**Success Metrics**: Answer quality, retrieval accuracy, response coherence\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Track 2: Embedding Model Showdown**\n",
    "**The Question**: Which embedding model gives the best retrieval results?\n",
    "\n",
    "**Models to Compare:**\n",
    "- `all-MiniLM-L6-v2` (what we used - fast and small)\n",
    "- `all-mpnet-base-v2` (larger, potentially better quality)\n",
    "- `sentence-transformers/all-MiniLM-L12-v2` (larger variant)\n",
    "- Domain-specific models for your document type\n",
    "\n",
    "**Success Metrics**: Retrieval precision, answer relevance, speed comparison\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Track 3: Retrieval Strategy Enhancement**\n",
    "**The Question**: How many chunks should we retrieve and how should we rank them?\n",
    "\n",
    "**Experiments to Try:**\n",
    "- **Retrieval count**: Test 1, 3, 5, 10 retrieved chunks\n",
    "- **Similarity thresholds**: Only use chunks above 0.5, 0.7, 0.8 similarity\n",
    "- **Re-ranking**: Use different similarity metrics\n",
    "- **Context limits**: How much context can the model handle effectively?\n",
    "\n",
    "**Success Metrics**: Answer completeness, hallucination reduction, context utilization\n",
    "\n",
    "---\n",
    "\n",
    "### üìö **Track 4: Multi-Document Mastery**\n",
    "**The Question**: How well does RAG work with multiple different documents?\n",
    "\n",
    "**Experiments to Try:**\n",
    "- Upload 2-3 different PDFs and ask cross-document questions\n",
    "- Test document type mixing (PDFs + text files + web content)\n",
    "- Source attribution: Can you track which document answered what?\n",
    "- Conflicting information: How does the system handle contradictions?\n",
    "\n",
    "**Success Metrics**: Cross-document reasoning, source accuracy, conflict resolution\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° **Track 5: Real-World Application**\n",
    "**The Question**: Can you build something actually useful?\n",
    "\n",
    "**Project Ideas:**\n",
    "- **Study Assistant**: Upload your course materials, create a personal tutor\n",
    "- **Research Helper**: Upload papers from your field, ask comparative questions\n",
    "- **Policy Bot**: Upload company/school policies, create an internal help system\n",
    "- **Personal Knowledge Base**: Upload your notes, papers, articles\n",
    "\n",
    "**Success Metrics**: Practical utility, user satisfaction, real-world accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### üìä **Track 6: Evaluation & Quality Analysis**\n",
    "**The Question**: How do we measure if our RAG system is actually good?\n",
    "\n",
    "**Evaluation Methods to Build:**\n",
    "- **Answer quality rubric**: Rate responses on accuracy, relevance, completeness\n",
    "- **Retrieval evaluation**: Check if the right chunks were found\n",
    "- **Speed benchmarking**: Measure response times across configurations\n",
    "- **Hallucination detection**: Identify when the model makes things up\n",
    "\n",
    "**Success Metrics**: Systematic quality measurement, performance optimization\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **Documentation Tips**\n",
    "\n",
    "As you experiment, keep track of:\n",
    "- ‚úÖ **What you tried** (specific configurations, parameters)\n",
    "- ‚úÖ **What worked** (successful approaches and why)\n",
    "- ‚úÖ **What didn't work** (failures teach us too!)\n",
    "- ‚úÖ **Surprising discoveries** (unexpected results often lead to breakthroughs)\n",
    "- ‚úÖ **Practical insights** (what would you use in a real project?)\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù **Collaboration Encouraged!**\n",
    "\n",
    "- **Team up** with classmates to tackle different tracks\n",
    "- **Share findings** - compare results across different approaches\n",
    "- **Peer review** each other's experiments\n",
    "- **Present discoveries** to the class\n",
    "\n",
    "---\n",
    "\n",
    "## üåü **Remember**\n",
    "\n",
    "> *\"The best way to understand RAG is not just to build it, but to break it, improve it, and push its boundaries.\"*\n",
    "\n",
    "**Every expert started as a curious experimenter. Every breakthrough began with someone asking \"What if...?\"**\n",
    "\n",
    "Ready to become a RAG researcher? Pick your track and start experimenting! üöÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
